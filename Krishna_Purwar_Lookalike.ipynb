{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "jSxo3hfE2Ncf"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the datasets from CSV files\n",
        "df_customers = pd.read_csv(\"https://raw.githubusercontent.com/i183x/zeo/refs/heads/main/Customers.csv\")\n",
        "df_products = pd.read_csv(\"https://raw.githubusercontent.com/i183x/zeo/refs/heads/main/Products.csv\")\n",
        "df_transactions = pd.read_csv(\"https://raw.githubusercontent.com/i183x/zeo/refs/heads/main/Transactions.csv\")\n"
      ],
      "metadata": {
        "id": "3Ku1wicn2O1G"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_transactions = df_transactions.drop('Price', axis=1) #it is duplicate\n",
        "# Merge the datasets to have customer, product, and transaction data together\n",
        "df = df_transactions.merge(df_customers, on='CustomerID', how='left')\n",
        "df = df.merge(df_products, on='ProductID', how='left')"
      ],
      "metadata": {
        "id": "nEd1zn-42Vfn"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import json\n",
        "\n",
        "# Preprocessing: Combine relevant features into a single representation for each customer\n",
        "def preprocess_customer_data(df):\n",
        "    # Combine product history for each customer\n",
        "    df['TransactionHistory'] = df.groupby('CustomerID')['ProductName'].transform(lambda x: ' '.join(x))\n",
        "\n",
        "    # Aggregate numerical features\n",
        "    df['TotalSpent'] = df.groupby('CustomerID')['TotalValue'].transform('sum')\n",
        "    df['TotalTransactions'] = df.groupby('CustomerID')['TransactionID'].transform('nunique')\n",
        "\n",
        "    # Ensure each customer has unique rows\n",
        "    customer_data = df[['CustomerID', 'Region', 'SignupDate', 'TransactionHistory', 'TotalSpent', 'TotalTransactions']]\n",
        "    customer_data = customer_data.drop_duplicates(subset=['CustomerID'])\n",
        "\n",
        "    # Normalize TotalSpent and TotalTransactions\n",
        "    scaler = StandardScaler()\n",
        "    customer_data[['TotalSpent', 'TotalTransactions']] = scaler.fit_transform(customer_data[['TotalSpent', 'TotalTransactions']])\n",
        "\n",
        "    return customer_data\n",
        "\n",
        "# Function to get top N similar customers for a given customer ID\n",
        "def get_top_n_similar(customer_id, similarity_matrix, customer_ids, n=3):\n",
        "    index = customer_ids.index(customer_id)\n",
        "    similarity_scores = list(enumerate(similarity_matrix[index]))\n",
        "    sorted_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Exclude the customer itself and return the top N\n",
        "    top_n = [(customer_ids[i], score) for i, score in sorted_scores if customer_ids[i] != customer_id][:n]\n",
        "    return top_n\n",
        "\n",
        "# --- Main Execution ---\n",
        "# Assuming `df` is the input DataFrame with customer data (defined elsewhere)\n",
        "\n",
        "# Step 1: Preprocess the customer data\n",
        "customer_data = preprocess_customer_data(df)\n",
        "\n",
        "# Step 2: Combine all text-based features into one for vectorization\n",
        "customer_data['CombinedFeatures'] = (\n",
        "    customer_data['Region'] + ' ' +\n",
        "    customer_data['TransactionHistory'].fillna('')\n",
        ")\n",
        "\n",
        "# Step 3: TF-IDF Vectorization\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)  # max_features limits the number of terms used\n",
        "feature_matrix = vectorizer.fit_transform(customer_data['CombinedFeatures'])\n",
        "\n",
        "# Step 4: Include TotalSpent and TotalTransactions (numerical features) into the feature matrix\n",
        "numerical_features = customer_data[['TotalSpent', 'TotalTransactions']].values\n",
        "numerical_feature_matrix = np.array(numerical_features)\n",
        "\n",
        "# Step 5: Combine text-based and numerical features (stack them horizontally)\n",
        "final_feature_matrix = np.hstack([feature_matrix.toarray(), numerical_feature_matrix])\n",
        "\n",
        "# Step 6: Calculate cosine similarity among all customers\n",
        "similarity_matrix = cosine_similarity(final_feature_matrix)\n",
        "\n",
        "# Step 7: Get the top 3 similar customers for the first 20 customers\n",
        "customer_ids = customer_data['CustomerID'].tolist()\n",
        "lookalike_map = {}\n",
        "\n",
        "# Iterate over first 20 customers (C0001 to C0020)\n",
        "for customer_id in customer_ids[:20]:\n",
        "    top_similar = get_top_n_similar(customer_id, similarity_matrix, customer_ids, n=3)\n",
        "    # Convert to the desired format: [{SimilarCustomerID: SimilarityScore}, ...]\n",
        "    lookalike_map[customer_id] = [{similar_id: score} for similar_id, score in top_similar]\n",
        "\n",
        "# Step 8: Save the results to Lookalike.csv in the required format\n",
        "output_data = []\n",
        "\n",
        "for customer_id, similar_list in lookalike_map.items():\n",
        "    # Format the list correctly as a string\n",
        "    lookalikes_str = '[' + ', '.join([f'{{{k}: {v}}}' for d in similar_list for k, v in d.items()]) + ']'\n",
        "    output_data.append({\n",
        "        'cust_id': customer_id,\n",
        "        'List': lookalikes_str  # List of dictionaries in string format\n",
        "    })\n",
        "\n",
        "# Convert the list of dicts into a DataFrame\n",
        "lookalike_df = pd.DataFrame(output_data)\n",
        "\n",
        "# Save to CSV\n",
        "lookalike_df.to_csv('Krishna_Purwar_Lookalike.csv', index=False)\n",
        "\n",
        "print(\"Lookalike Model executed successfully. Results saved to Lookalike.csv.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpoYzEAzA0jp",
        "outputId": "1c5e8373-c8ed-4865-ce0a-005c05801c87"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lookalike Model executed successfully. Results saved to Lookalike.csv.\n"
          ]
        }
      ]
    }
  ]
}